# ruOpenBookQA

## Описание задачи

**ruOpenBookQA** — это QA датасет с четырьмя вариантами ответов (из которых только один правильный) на научные вопросы элементарного уровня, которые проверяют понимание более чем 1 тыс. основных научных фактов. Датасет создан на основе оригинального английского набора данных [1], вручную русифицирован и провалидирован. Датасет является частью бенчмарка [TAPE](https://tape-benchmark.com/) [2], который был переработан в инструкционный и отфильтрован.

**Тип задания:**  многоклассовая классификация, выбор из четырех вариантов ответов

**Ключевые слова:** логика, знания о мире, здравый смысл

**Авторы:** Екатерина Такташева, Татьяна Шаврина, Алена Феногенова, Денис Шевелёв, Надежда Катричева, Мария Тихонова,  Альбина Ахметгареева, Олег Зинкевич, Анастасия Башмакова, Светлана Иорданская, Алена Спиридонова, Валентина Куренщикова, Екатерина Артемова, Владислав Михайлов

## Мотивация

ruOpenBookQA основан на работе [1]. Оригинальный OpenBookQA — это QA датасет с четырьмя ответами на вопросы, созданный на основе экзаменов по естествознанию для оценки человеческого понимания. Английский вариант состоит из 5957 вопросов элементарного уровня по вопросам биологии, химии, физики с несколькими вариантами ответов из которых 1 ответ правильный. Вопросы проверяют понимание набора из 1326 основных научных фактов и применение этих фактов в различных ситуациях. Ответы на вопросы OpenBookQA требуют дополнительных общих знаний о мире и логике. На вопросы нельзя ответить поиском во внешнюю базу знаний или настроив алгоритм совпадения слов, необходимо “понимание языка”. Русская версия набора намного меньше, но охватывает темы, типичные для русского языка.

## Описание датасета

### Поля данных

- meta — метаинформация о задании:
    - id — номер примера в датасете;
- instruction — инструктивный промпт заданный под текущее задание;
- inputs — словарь, который содержит следующую информацию:
    - question — вопрос теста;
    - option_a — опция A;
    - option_b — опция B;
    - option_c — опция C;
    - option_d — опция D;
- outputs — ответ, может быть одни из следующих строковых переменных: A, B, C, D.

### Примеры данных

Каждый пример выглядит следующим образом:

```jsx
{
    "instruction": "{text}\\nA. {option_a}\\nB. {option_b}\\nC. {option_c}\\nD. {option_d}\\nКакой ответ является правильным? В качестве ответа запишите только букву верного варианта: A, B, C или D без дополнительных объяснений.\\nОтвет: ",
    "inputs": {
        "question": "Что вращается вокруг своей оси?",
        "option_a": "океаны",
        "option_b": "ветры",
        "option_c": "шар голубой",
        "option_d": "люди"
    },
    "outputs": "C",
    "meta": {
        "id": "14-167"
    }
}
```

### Разбиение данных

Количество тренировочных примеров в датасете: 2338, и 400 тестовых.

### Промпты

Промпты представлены в виде инструкции, всего 10 различных промптов.

Примеры промта:

```jsx
"{text}\\nA. {option_a}\\nB. {option_b}\\nC. {option_c}\\nD. {option_d}\\nКакой ответ является правильным? В качестве ответа запишите только букву верного варианта: A, B, C или D без дополнительных объяснений.\\nОтвет:"
```

```jsx
"Опираясь на логику и общеизвестные факты, ответьте на вопрос: {text}\\nA) {option_a}\\nB) {option_b}\\nC) {option_c}\\nD) {option_d}\\nВ качестве ответа запишите только букву верного варианта: A, B, C или D без дополнительных объяснений.\\nОтвет:"
```

### Создание Датасета

Вопросы взяты из исходного (английского) набора данных OpenBookQA, созданного с помощью многоэтапного краудсорсинга и частичной экспертной фильтрации. Набор данных в основном состоит из автоматического перевода английского OpenBookQA, а также ручных проверок и русификации примеров. Для инструкционной версии сета,  мы исключили из закрытого теста примеры, вошедшие в BigBench.

## Оценка

### Метрики

В качестве метрик используются среднее макро F1 (Average Macro F1) и точность (Accuracy).

### Человеческая оценка

Человеческая оценка измерена с помощью платформы Яндекс.Толока с перекрытием разметчиков 3.

Результаты F1 среднего макро и точности: 87.5 / 86.5, соответсвенно.

## Литература

- [1] Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal. 2018. Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering. In *Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,* pages 2381–2391, Brussels, Belgium. Association for Computational Linguistics.
- [2] Taktasheva, Ekaterina, et al. "TAPE: Assessing Few-shot Russian Language Understanding." *Findings of the Association for Computational Linguistics: EMNLP 2022.*
