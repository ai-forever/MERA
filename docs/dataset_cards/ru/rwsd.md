# RWSD

## Описание

**Russian Winograd Schema Dataset (RWSD)** - это задание, в котором в предложении выделено два текстовых фрагмента. Задача состоит в том, чтобы определить, употреблены ли они в одном смысле или в разных. Схема берет свое имя из известного примера Терри Винограда.

Корпус заданий составлен как вызов для ИИ в соответствии с тестом Тьюринга. Одним из плюсов такой постановки задания является простая форма машинного ответа, и ответы системы делают даже для неспециалистов очевидным недостаток в знаниях проблемы в понимании задания машиной. Сделан на основе английского [сета аналога](https://cdn.aaai.org/ocs/4492/4492-21843-1-PB.pdf) [1, 2], входит в [Russian SuperGLUE](https://russiansuperglue.com/tasks/task_info/RWSD) [3].

**Тип задачи:**  Логика и аргументация, знания о мире. Бинарная классификация: да/нет

**Ключевые слова:** Логика, Знания о мире, Здравый смысл

**Авторы:** Татьяна Шаврина, Алена Феногенова, Валентин Малых, Екатерина Артемова, Владислав Михайлов, Мария Тихонова, Денис Шевелёв, Антон Емельянов, Андрей Евлампиев

## Мотивация

Датасет проверяет способности моделей выявлять и разрешать синтаксическую неоднозначность, используя логику и знания о мире. Классический сет Терри Винограда. Датасет в бенчмарке RussianSuperGLUE один из немногих, для которых всё ещё сохраняется значительный разрыв между оценками моделей и человеческой.

## Описание Датасета

### Поля датасета

- meta — метаинформация о задаче:
    - id — номер примера в датасете;
- instruction — строка содержащая инструкции для задания;
- inputs — словарь, содержащий следующую информацию:
    - text — текст, содержащий исходную ситуацию, обычно предложение, которое содержит некоторую синтаксическую неоднозначность;
    - span1_index и span_text — индекс начала слова и само слово - объект ситуации (референт);
    - span2_index и span2_text — индекс начала слова и само слово - (анафор) обычно местоимение, для которого требуется определить, употребляется ли оно в том же смысле что и референт или нет;
- outputs — строка с бинарным ответом (Да или Нет).

### Примеры Данных

Каждый пример выглядит следующим образом:

```jsx
{
    "instruction": "Дан небольшой текст: \\"{text}\\"\\nОбъект из текста: \\"{span1_text}\\"\\nТекстовый фрагмент, который может относиться к двум или нескольким объектам в тексте, включая указанный: \\"{span2_text}\\"\\nНужно ответить, относится ли фрагмент к названному объекту. Ответь Да, если относится, или Нет.",
    "inputs": {
         "text": "Женя поблагодарила Сашу за помощь, которую она оказала.",
         "span1_index": 2,
         "span1_text": "Сашу",
	 "span2_index": 6,
	 "span2_text": "она оказала"
     },
     "outputs": "Да",
     "meta": {"id": 11}
}
```

### Разбиение данных

Количество обучающих примеров в датаcете равно 606, валидационных — 204, тестовых — 260.

### Промпты

Промпты представлены в виде инструкций, в которых даны текст, обозначены вставки для выделенных слов, и объяснено как модели отвечать.  Для задания подобраны 10 инструкций разной сложности.

Пример промпта:

```jsx
"Перед тобой текст: \\"{text}\\"\\nОпираясь на текст, скажи, относится ли местоимение во фрагменте текста \\"{span2_text}\\" к объекту фрагмента \\"{span1_text}\\"? В качестве ответа выдай одно слово: Да, если относится, или Нет, если не относится. Напиши только правильный ответ без дополнительных объяснений."
```

### Создание датасета

Датасет создан на основе соотвествующего датасета из Russian SuperGLUE [3], тестовая часть была дополнительна выверена и дополнена новыми примера для баланса классов (баланс классов 130 на 130 примеров).  Все примеры для исходного сета из Russian SuperGLUE были переведены в инструктивный формат.

## Оценка

### Метрики

В качестве метрики для оценки качества на данном датасете используется точность (Accuracy).

### Человеческая оценка

Человеческая оценка производилась с помощью платформы Яндекс.Толока с перекрытием разметчиков равным 5.

Финальная оценка точности человека: **0.835**

## Список литературы

[1] Levesque, H. J., Davis, E., & Morgenstern, L. (2012). The winograd schema challenge. In *13th International Conference on the Principles of Knowledge Representation and Reasoning, KR 2012* (pp. 552-561). (Proceedings of the International Conference on Knowledge Representation and Reasoning). Institute of Electrical and Electronics Engineers Inc.

[2] Wang A. et al. Superglue: A stickier benchmark for general-purpose language understanding systems //Advances in Neural Information Processing Systems. – 2019. – С. 3261-3275.

[3] Tatiana Shavrina, Alena Fenogenova, Emelyanov Anton, Denis Shevelev, Ekaterina Artemova, Valentin Malykh, Vladislav Mikhailov, Maria Tikhonova, Andrey Chertok, and Andrey Evlampiev. 2020. RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark. In *Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),* pages 4717–4726, Online. Association for Computational Linguistics.
